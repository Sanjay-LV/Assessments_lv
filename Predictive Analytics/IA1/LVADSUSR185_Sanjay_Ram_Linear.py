# -*- coding: utf-8 -*-
"""Predictive_analytics_IA1_Linear_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KDADQUE9sX72qW-v8hUNokMzrJ05vJ9I
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
df = pd.read_csv("/content/expenses.csv")
df.head(10)

df.info()
df.describe()

"""1. Handling missing values and Outliers"""

df.isna().sum()

median_fill = df['bmi'].median()
df['bmi'] = df['bmi'].fillna(median_fill)

df.isna().sum()

#Outliers detection

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

for column in numerical_columns:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()


q1 = np.percentile(df['charges'], 25)
q3 = np.percentile(df['charges'], 75)
iqr = q3 - q1

# Calculate outlier bounds
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)

# Identify outliers
outliers = [charge for charge in df['charges'] if charge < lower_bound or charge > upper_bound]
print("Outliers:", outliers)
len(outliers)

"""2.Encoding Categorical Data"""

from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()
df['sex'] = label.fit_transform(df['sex'])
df['smoker'] = label.fit_transform(df['smoker'])
df['region'] = label.fit_transform(df['region'])
df.head()

"""3.Feature selection and Data Cleaning"""

correlation_matrix = df.corr()
correlation_matrix

#No duplicate values present in the data
df.duplicated()

# Going to consider all the columns since every feature is important
# Even though correlation of sex,children and region is low w.r.t charges these are important features when viewed logically.
# So,no columns are being dropped from the dataset.

"""4. Data Splitting"""

X = df.drop(columns=['charges'])
y = df['charges']

y.head(5)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)

min_max_scaler = MinMaxScaler()
X_train = pd.DataFrame(min_max_scaler.fit_transform(X_train[list(X.columns)]),columns=X.columns)
X_test = pd.DataFrame(min_max_scaler.fit_transform(X_test[list(X.columns)]),columns=X.columns)

"""5.Model Development and Training"""

model = LinearRegression()
model.fit(X_train,y_train)

y_pred = model.predict(X_test)

"""6.Model Evaluation"""

from sklearn.metrics import mean_squared_error,r2_score
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

rmse = mean_squared_error(y_test, y_pred,squared=False)
print("Root Mean Squared Error:", rmse)

# Coefficients and intercept
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

r2_s = r2_score(y_test, y_pred)
print("R2 Score:", r2_s)